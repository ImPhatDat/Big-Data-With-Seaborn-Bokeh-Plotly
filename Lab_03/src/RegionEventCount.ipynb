{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as f\n",
    "findspark.init()\n",
    "\n",
    "# Creating a SparkSession in Python\n",
    "spark = SparkSession.builder\\\n",
    "    .master(\"local\")\\\n",
    "    .appName(\"Spark Streaming\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "# keep the size of shuffles small\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPath = cwd + \"/../data/sample\"\n",
    "outputPath = cwd + \"/../output_3\"\n",
    "checkpointPath = cwd + \"/../checkpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_schema = StructType([StructField(f\"_c{i}\", StringType(), nullable=True) for i in range(22)])\n",
    "\n",
    "# define schema for yellow taxi trips\n",
    "yellow_taxi_schema = StructType([\n",
    "    StructField(\"type\", StringType(), nullable=False),\n",
    "    StructField(\"VendorID\", IntegerType()),\n",
    "    StructField(\"tpep_pickup_datetime\", TimestampType()),\n",
    "    StructField(\"tpep_dropoff_datetime\", TimestampType()),\n",
    "    StructField(\"passenger_count\", IntegerType()),\n",
    "    StructField(\"trip_distance\", FloatType()),\n",
    "    StructField(\"pickup_longitude\", FloatType()),\n",
    "    StructField(\"pickup_latitude\", FloatType()),\n",
    "    StructField(\"RatecodeID\", FloatType()),\n",
    "    StructField(\"store_and_fwd_flag\", StringType()),\n",
    "    StructField(\"dropoff_longitude\", FloatType()),\n",
    "    StructField(\"dropoff_latitude\", FloatType()),\n",
    "    StructField(\"payment_type\", IntegerType()),\n",
    "    StructField(\"fare_amount\", FloatType()),\n",
    "    StructField(\"extra\", FloatType()),\n",
    "    StructField(\"mta_tax\", FloatType()),\n",
    "    StructField(\"tip_amount\", FloatType()),\n",
    "    StructField(\"tolls_amount\", FloatType()),\n",
    "    StructField(\"improvement_surcharge\", FloatType()),\n",
    "    StructField(\"total_amount\", FloatType())\n",
    "])\n",
    "# define schema for green taxi trips\n",
    "green_taxi_schema = StructType([\n",
    "    StructField(\"type\", StringType(), nullable=False),\n",
    "    StructField(\"VendorID\", IntegerType()),\n",
    "    StructField(\"lpep_pickup_datetime\", TimestampType()),\n",
    "    StructField(\"Lpep_dropoff_datetime\", TimestampType()),\n",
    "    StructField(\"Store_and_fwd_flag\", StringType()),\n",
    "    StructField(\"RateCodeID\", IntegerType()),\n",
    "    StructField(\"Pickup_longitude\", FloatType()),\n",
    "    StructField(\"Pickup_latitude\", FloatType()),\n",
    "    StructField(\"Dropoff_longitude\", FloatType()),\n",
    "    StructField(\"Dropoff_latitude\", FloatType()),\n",
    "    StructField(\"Passenger_count\", IntegerType()),\n",
    "    StructField(\"Trip_distance\", FloatType()),\n",
    "    StructField(\"Fare_amount\", FloatType()),\n",
    "    StructField(\"Extra\", FloatType()),\n",
    "    StructField(\"MTA_tax\", FloatType()),\n",
    "    StructField(\"Tip_amount\", FloatType()),\n",
    "    StructField(\"Tolls_amount\", FloatType()),\n",
    "    StructField(\"Ehail_fee\", FloatType()),\n",
    "    StructField(\"improvement_surcharge\", FloatType()),\n",
    "    StructField(\"Total_amount\", FloatType()),\n",
    "    StructField(\"Payment_type\", IntegerType()),\n",
    "    StructField(\"Trip_type\", IntegerType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the entire data files first\n",
    "full_df = spark.readStream\\\n",
    "    .option(\"maxFilesPerTrigger\", 100)\\\n",
    "    .csv(f\"file://{inputPath}\",\n",
    "         header=False,\n",
    "         schema=full_schema)\n",
    "\n",
    "# Filter rows based on the 'type' column\n",
    "yellow_df = full_df.where(full_df[\"_c0\"] == \"yellow\").selectExpr(\n",
    "    *[f\"cast(_c{i} as {field.dataType.simpleString()}) as {field.name}\" \\\n",
    "        for i, field in enumerate(yellow_taxi_schema.fields)]\n",
    ")\n",
    "\n",
    "green_df = full_df.where(full_df[\"_c0\"] == \"green\").selectExpr(\n",
    "    *[f\"cast(_c{i} as {field.dataType.simpleString()}) as {field.name}\" \\\n",
    "        for i, field in enumerate(green_taxi_schema.fields)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_yellow = yellow_df.selectExpr(\"tpep_dropoff_datetime as dropoff_datetime\",\n",
    "                                  \"dropoff_longitude\", \n",
    "                                  \"dropoff_latitude\")\n",
    "sub_green = green_df.selectExpr(\"Lpep_dropoff_datetime as dropoff_datetime\",\n",
    "                                \"Dropoff_longitude as dropoff_longitude\", \n",
    "                                \"Dropoff_latitude as dropoff_latitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = sub_yellow.union(sub_green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goldman = [[-74.0141012, 40.7152191], [-74.013777, 40.7152275], \n",
    "           [-74.0141027, 40.7138745], [-74.0144185, 40.7140753]]\n",
    "citigroup = [[-74.011869, 40.7217236], [-74.009867, 40.721493], \n",
    "             [-74.010140,40.720053], [-74.012083, 40.720267]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@f.udf(returnType=BooleanType())\n",
    "def in_polygon(x, y, polygon):\n",
    "    num_vertices = len(polygon)\n",
    "    inside = False\n",
    "    \n",
    "    # Store the first point in the polygon and initialize the second point\n",
    "    p1 = polygon[0]\n",
    "    \n",
    "    # Loop through each edge in the polygon\n",
    "    for i in range(1, num_vertices + 1):\n",
    "        # Get the next point in the polygon\n",
    "        p2 = polygon[i % num_vertices]\n",
    "        \n",
    "        # Check if the point is above the minimum y coordinate of the edge\n",
    "        if y > min(p1[1], p2[1]):\n",
    "            # Check if the point is below the maximum y coordinate of the edge\n",
    "            if y <= max(p1[1], p2[1]):\n",
    "                # Check if the point is to the left of the maximum x coordinate of the edge\n",
    "                if x <= max(p1[0], p2[0]):\n",
    "                    # Calculate the x-intersection of the line connecting the point to the edge\n",
    "                    x_intersection = (y - p1[1]) * (p2[0] - p1[0]) / (p2[1] - p1[1]) + p1[0]\n",
    "                    \n",
    "                    # Check if the point is on the same line as the edge or to the left of the x-intersection\n",
    "                    if p1[0] == p2[0] or x <= x_intersection:\n",
    "                        # Flip the inside flag\n",
    "                        inside = not inside\n",
    "                        \n",
    "        # Store the current point as the first point for the next iteration\n",
    "        p1 = p2\n",
    "    # Return the value of the inside flag\n",
    "    return inside\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = sub_df\\\n",
    "    .withColumn(\"goldman\", in_polygon(\"dropoff_longitude\", \"dropoff_latitude\", f.lit(goldman)))\\\n",
    "    .withColumn(\"citigroup\", in_polygon(\"dropoff_longitude\", \"dropoff_latitude\", f.lit(citigroup)))\n",
    "    \n",
    "# filter out\n",
    "processed_df = processed_df.where(\"goldman == 1 OR citigroup == 1\")\n",
    "processed_df = processed_df.withColumn(\"headquarter\", f.when(f.col(\"goldman\") == 1, \"goldman\").otherwise(\"citigroup\"))\n",
    "\n",
    "by_dropoff = processed_df.groupBy(f.window(f.col(\"dropoff_datetime\"), \"1 hour\"), \"headquarter\")\\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foreach_batch_function(batch_df, epoch_id):\n",
    "    # get endHour column\n",
    "    tmp_df = batch_df.withColumn(\"startHour\", f.hour(f.col(\"window.start\")))\n",
    "    \n",
    "    # for each endHour, write to different directory\n",
    "    start_hours = tmp_df.select(\"startHour\").distinct().collect()\n",
    "    \n",
    "    if len(start_hours) != 0:\n",
    "        for start_hour in start_hours:\n",
    "            h_num = start_hour['startHour']\n",
    "            hour_df = tmp_df.where(f.col(\"startHour\") == f.lit(h_num)).select(\"headquarter\", \"count\")\n",
    "            output_dir = f\"file://{outputPath}/output-{(h_num + 1) * 60 * 60 * 1000}\"\n",
    "            \n",
    "            hour_df.write.mode(\"overwrite\").csv(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = by_dropoff.writeStream\\\n",
    "    .outputMode(\"update\")\\\n",
    "    .foreachBatch(foreach_batch_function)\\\n",
    "    .queryName(\"Region_Event_Count\")\\\n",
    "    .option(\"checkpointLocation\", f\"file://{cwd}/../checkpoint\")\\\n",
    "    .start()\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
